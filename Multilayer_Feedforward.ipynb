{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeTdIptvnsMA",
        "outputId": "0621c958-582f-4e56-b9a1-d0ab30b9b306"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.9.0+cu102\n",
            "  Downloading https://download.pytorch.org/whl/cu102/torch-1.9.0%2Bcu102-cp38-cp38-linux_x86_64.whl (831.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 831.4 MB 13 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.10.0+cu102\n",
            "  Downloading https://download.pytorch.org/whl/cu102/torchvision-0.10.0%2Bcu102-cp38-cp38-linux_x86_64.whl (22.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.1 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting torchaudio===0.9.0\n",
            "  Downloading torchaudio-0.9.0-cp38-cp38-manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.9.0+cu102) (4.4.0)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision==0.10.0+cu102) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision==0.10.0+cu102) (1.21.6)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.0+cu116\n",
            "    Uninstalling torch-1.13.0+cu116:\n",
            "      Successfully uninstalled torch-1.13.0+cu116\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.14.0+cu116\n",
            "    Uninstalling torchvision-0.14.0+cu116:\n",
            "      Successfully uninstalled torchvision-0.14.0+cu116\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 0.13.0+cu116\n",
            "    Uninstalling torchaudio-0.13.0+cu116:\n",
            "      Successfully uninstalled torchaudio-0.13.0+cu116\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.14.0 requires torch==1.13.0, but you have torch 1.9.0+cu102 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.9.0+cu102 torchaudio-0.9.0 torchvision-0.10.0+cu102\n"
          ]
        }
      ],
      "source": [
        "!pip3 install torch==1.9.0+cu102 torchvision==0.10.0+cu102 torchaudio===0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "s_l5Mq5InxQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "y8zVCdhqpWvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 784 # 28x28\n",
        "hidden_size = 500\n",
        "num_classes = 10\n",
        "num_epochs = 10\n",
        "batch_size = 100\n",
        "learning_rate = 0.001"
      ],
      "metadata": {
        "id": "Z07FQjBZn9dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import MNIST dataset\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                            train=True,\n",
        "                                       transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                           train=False,\n",
        "                                           transform=transforms.ToTensor())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upz-b828n9gQ",
        "outputId": "53ded051-d93f-4dda-c54d-ccdcdbff8d44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                            batch_size=batch_size,\n",
        "                                            shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=False)"
      ],
      "metadata": {
        "id": "exCMpULJn9i4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = iter(test_loader)\n",
        "example_data, example_targets = examples.next()\n",
        "for i in range(6):\n",
        "  plt.subplot(2,3,i+1)\n",
        "  plt.imshow(example_data[i][0], cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "KNn0TBRwn9lX",
        "outputId": "b81cff90-ea29-4a99-ca58-0f17941aa2d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2 layer multi layer feedforward network\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.l1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.l1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.l2(out)\n",
        "        # no activation and no softmax at the end\n",
        "        return out"
      ],
      "metadata": {
        "id": "P6BKAg5ipezr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNet(input_size, hidden_size, num_classes).to(device)"
      ],
      "metadata": {
        "id": "54gWjR3IpD8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "8jDhkzEkpJKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # origin shape: [100, 1, 28, 28]\n",
        "        # resized: [100, 784]\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df3o-SE5pkom",
        "outputId": "12cf04f2-dcd9-41fb-d4b1-6364a1363efb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [100/600], Loss: 0.4666\n",
            "Epoch [1/10], Step [200/600], Loss: 0.3426\n",
            "Epoch [1/10], Step [300/600], Loss: 0.2437\n",
            "Epoch [1/10], Step [400/600], Loss: 0.1858\n",
            "Epoch [1/10], Step [500/600], Loss: 0.2852\n",
            "Epoch [1/10], Step [600/600], Loss: 0.1561\n",
            "Epoch [2/10], Step [100/600], Loss: 0.1643\n",
            "Epoch [2/10], Step [200/600], Loss: 0.1477\n",
            "Epoch [2/10], Step [300/600], Loss: 0.0710\n",
            "Epoch [2/10], Step [400/600], Loss: 0.1168\n",
            "Epoch [2/10], Step [500/600], Loss: 0.1137\n",
            "Epoch [2/10], Step [600/600], Loss: 0.2105\n",
            "Epoch [3/10], Step [100/600], Loss: 0.0735\n",
            "Epoch [3/10], Step [200/600], Loss: 0.0378\n",
            "Epoch [3/10], Step [300/600], Loss: 0.0834\n",
            "Epoch [3/10], Step [400/600], Loss: 0.0494\n",
            "Epoch [3/10], Step [500/600], Loss: 0.0377\n",
            "Epoch [3/10], Step [600/600], Loss: 0.0487\n",
            "Epoch [4/10], Step [100/600], Loss: 0.0385\n",
            "Epoch [4/10], Step [200/600], Loss: 0.0250\n",
            "Epoch [4/10], Step [300/600], Loss: 0.0917\n",
            "Epoch [4/10], Step [400/600], Loss: 0.0472\n",
            "Epoch [4/10], Step [500/600], Loss: 0.0146\n",
            "Epoch [4/10], Step [600/600], Loss: 0.0761\n",
            "Epoch [5/10], Step [100/600], Loss: 0.1236\n",
            "Epoch [5/10], Step [200/600], Loss: 0.0251\n",
            "Epoch [5/10], Step [300/600], Loss: 0.0308\n",
            "Epoch [5/10], Step [400/600], Loss: 0.0120\n",
            "Epoch [5/10], Step [500/600], Loss: 0.0427\n",
            "Epoch [5/10], Step [600/600], Loss: 0.0358\n",
            "Epoch [6/10], Step [100/600], Loss: 0.0309\n",
            "Epoch [6/10], Step [200/600], Loss: 0.0610\n",
            "Epoch [6/10], Step [300/600], Loss: 0.0440\n",
            "Epoch [6/10], Step [400/600], Loss: 0.0129\n",
            "Epoch [6/10], Step [500/600], Loss: 0.0404\n",
            "Epoch [6/10], Step [600/600], Loss: 0.0384\n",
            "Epoch [7/10], Step [100/600], Loss: 0.0089\n",
            "Epoch [7/10], Step [200/600], Loss: 0.0263\n",
            "Epoch [7/10], Step [300/600], Loss: 0.0246\n",
            "Epoch [7/10], Step [400/600], Loss: 0.0636\n",
            "Epoch [7/10], Step [500/600], Loss: 0.0374\n",
            "Epoch [7/10], Step [600/600], Loss: 0.0272\n",
            "Epoch [8/10], Step [100/600], Loss: 0.0139\n",
            "Epoch [8/10], Step [200/600], Loss: 0.0028\n",
            "Epoch [8/10], Step [300/600], Loss: 0.0121\n",
            "Epoch [8/10], Step [400/600], Loss: 0.0272\n",
            "Epoch [8/10], Step [500/600], Loss: 0.0265\n",
            "Epoch [8/10], Step [600/600], Loss: 0.0048\n",
            "Epoch [9/10], Step [100/600], Loss: 0.0136\n",
            "Epoch [9/10], Step [200/600], Loss: 0.0108\n",
            "Epoch [9/10], Step [300/600], Loss: 0.0013\n",
            "Epoch [9/10], Step [400/600], Loss: 0.0018\n",
            "Epoch [9/10], Step [500/600], Loss: 0.0026\n",
            "Epoch [9/10], Step [600/600], Loss: 0.0386\n",
            "Epoch [10/10], Step [100/600], Loss: 0.0177\n",
            "Epoch [10/10], Step [200/600], Loss: 0.0097\n",
            "Epoch [10/10], Step [300/600], Loss: 0.0052\n",
            "Epoch [10/10], Step [400/600], Loss: 0.0146\n",
            "Epoch [10/10], Step [500/600], Loss: 0.0034\n",
            "Epoch [10/10], Step [600/600], Loss: 0.0039\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        # max returns (value ,index)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network on the 10000 test images: {acc} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLMkH6_epkrd",
        "outputId": "99659b24-31e0-4b62-cb24-a620d91c8e0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 98.05 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6hFaykaupktu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "upiBFbnnpkwW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}